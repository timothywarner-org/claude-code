{
  "memory_items": [
    {
      "id": "mem-001",
      "type": "pattern",
      "title": "MCP Memory Server - Complete Architecture and Implementation Guide",
      "summary": "MCP server architecture guide covering tools/resources/prompts primitives, JSON storage, FastMCP decorators, and the helper function pattern for inter-tool communication.",
      "content": "This document provides an exhaustive and comprehensive overview of the MCP (Model Context Protocol) Memory Server architecture that we are building for the O'Reilly Live Learning course titled 'Claude Code and Large-Context Reasoning'. The course is a 4-hour intensive training session that focuses on teaching developers how to effectively leverage Claude Code CLI, MCP servers, agentic workflows, and custom skills for production software development.\n\nThe MCP specification defines three fundamental primitives that form the backbone of all MCP server implementations. First, we have Tools, which represent executable actions that Claude can invoke to perform operations on behalf of the user. Tools are the primary mechanism for Claude to interact with external systems, databases, APIs, and file systems. Each tool must have a well-defined schema that specifies its parameters, return types, and error conditions. Second, we have Resources, which represent read-only data endpoints that Claude can query to retrieve information without modifying any state. Resources are useful for exposing configuration data, system status, and reference information. Third, we have Prompts, which are reusable template strings that can be parameterized and invoked to generate consistent, well-structured prompts for specific use cases.\n\nFor our Memory Server implementation, we are using a JSON-based storage backend located at ./data/memory_items.json. This approach was chosen for several important reasons: simplicity of implementation for a course demo, human-readable format that students can inspect and modify, zero external dependencies (no database server required), and easy portability across different operating systems and environments.\n\nThe data schema for our memory items includes the following fields: id (a unique identifier following the pattern mem-XXX), type (one of: note, prd, snippet, decision, pattern, config, troubleshooting), title (a short descriptive title), content (the full content/description), tags (an array of categorization tags), project (the associated project name defaulting to 'general'), created_at (ISO 8601 timestamp), and updated_at (ISO 8601 timestamp).\n\nA critical architectural decision we made was to separate in-memory state from file persistence. This pattern enables several important capabilities: the ability to demonstrate CRUD operations without permanently modifying the source data, easy reset functionality that students can use if they accidentally corrupt the data, and atomic operations that don't require file locking or transaction management.\n\nFor tool registration, we use the FastMCP framework's @mcp.tool() decorator. This decorator handles all the boilerplate of schema generation, parameter validation, and JSON-RPC message formatting. The handler signature follows this pattern: def handler(param1: Type1, param2: Type2 = default) -> dict. The return format should be a dictionary containing success status, any relevant data, and error information if applicable.\n\nImplementation best practices learned during development: Always validate input parameters before processing. Use type hints consistently for better IDE support and runtime validation. Log to stderr (not stdout) because stdout is reserved for JSON-RPC communication. Handle exceptions gracefully and return structured error responses. Use helper functions for shared logic between tools to avoid the 'FunctionTool not callable' issue when one tool needs to call another.",
      "tags": ["mcp-server", "tool-use", "architecture"],
      "project": "memory-server",
      "created_at": "2026-01-10T14:30:00Z",
      "updated_at": "2026-01-15T09:15:00Z"
    },
    {
      "id": "mem-002",
      "type": "config",
      "title": "DeepSeek Integration - Token Optimization Pipeline Configuration",
      "summary": "DeepSeek API setup for token optimization via OpenAI-compatible SDK. Covers environment variables, tiktoken counting, caching with TTL, and retry logic.",
      "content": "This configuration document describes the complete setup and integration of the DeepSeek LLM API for our token optimization pipeline. The Memory Server includes a sophisticated optimization feature that uses DeepSeek's language model to intelligently compress verbose memory content while preserving all technically significant information such as code snippets, commands, configuration values, and technical terminology.\n\nThe DeepSeek API is accessed through the OpenAI-compatible SDK, which means we can use the standard OpenAI Python client library with a custom base URL. This is extremely convenient because it allows us to leverage existing OpenAI integrations and tooling. The configuration requires the following environment variables to be set in the src/.env file:\n\nOPENAI_API_KEY=your-deepseek-api-key-here\nOPENAI_BASE_URL=https://api.deepseek.com\nLLM_MODEL=deepseek-chat\n\nThe api_utils.py module provides two main client classes: DeepSeekClient and GitHubClient. The DeepSeekClient is the primary class used for token optimization. It implements lazy initialization to avoid API calls until actually needed, connection testing to verify API accessibility, token counting using tiktoken with the cl100k_base encoding (which provides accurate token counts compatible with most modern language models), and an in-memory cache with configurable TTL (time-to-live) to avoid redundant optimization calls for the same content.\n\nThe optimization process works as follows: First, we count the tokens in the original content using tiktoken. If the content is already under the target token budget (default 1500 tokens), we return it as-is with a message indicating no optimization was needed. If optimization is required, we check the cache first using a SHA256 hash of the content concatenated with the max_tokens parameter. If a valid cached result exists, we return it immediately. Otherwise, we construct an optimization prompt that instructs the LLM to condense the content while preserving all code snippets (syntax must remain intact), command-line commands (exact syntax preserved), configuration values (API keys, URLs, paths), file names and paths, technical terms and acronyms, and numbers and version strings.\n\nThe optimization prompt explicitly instructs the LLM to remove redundant explanations, conversational filler, and unnecessary context. The LLM is configured with a low temperature (0.3) to ensure consistent, deterministic outputs. We implement retry logic with exponential backoff (3 attempts total) to handle transient API failures gracefully.\n\nCache statistics can be retrieved using the get_cache_stats() method, which returns the total number of cached entries, the average reduction percentage achieved, and the total tokens saved across all cached optimizations. This is useful for demonstrating the effectiveness of the optimization pipeline during the course.\n\nTroubleshooting common issues: If you see 'DeepSeek client not initialized', check that your OPENAI_API_KEY is set correctly in src/.env. If optimizations are slow, this is normal - the API call takes 2-5 seconds depending on content length. Use the cache to avoid repeated calls. If token counts seem off, remember that different tokenizers produce different counts; we use cl100k_base which is a reasonable approximation for most models.",
      "tags": ["deepseek", "token-optimization", "configuration"],
      "project": "memory-server",
      "created_at": "2026-01-08T16:45:00Z",
      "updated_at": "2026-01-15T10:30:00Z"
    },
    {
      "id": "mem-003",
      "type": "decision",
      "title": "FastMCP vs Raw MCP SDK - Framework Selection Rationale",
      "summary": "ADR choosing FastMCP over raw MCP SDK. Benefits: decorator-based tools, auto-validation, simpler lifecycle. Tradeoff: less low-level control.",
      "content": "This architectural decision record documents our choice to use FastMCP instead of the raw MCP SDK for implementing the Memory Server. This decision was made after careful consideration of several factors including development speed, code maintainability, student learning curve, and production readiness.\n\nFastMCP is a high-level Python framework that wraps the official MCP SDK and provides a more Pythonic, decorator-based API for building MCP servers. It was created by the community to reduce boilerplate and make MCP server development more accessible. The framework is available on PyPI and can be installed with pip install fastmcp.\n\nThe primary advantages of FastMCP that led to our decision include: Decorator-based tool registration with @mcp.tool() that eliminates manual schema construction. Automatic Pydantic model generation from Python type hints, which means we get input validation for free. Built-in support for resources via @mcp.resource() and prompts via @mcp.prompt() decorators. Simplified server lifecycle management with mcp.run() that handles all the stdio transport setup. Better error messages and debugging output compared to the raw SDK.\n\nThe tradeoffs we accepted by choosing FastMCP include: An additional dependency beyond the core MCP SDK. Slightly less control over low-level protocol details (though this rarely matters in practice). The framework prints a startup banner to stderr which some users find distracting (can be suppressed with log_level='ERROR'). Some advanced features like custom transports require dropping down to the raw SDK.\n\nFor the course context, FastMCP is clearly the right choice because it allows students to focus on the concepts (tools, resources, prompts) rather than getting bogged down in protocol details. The 4-hour course format doesn't allow time for deep-diving into JSON-RPC message formatting and stdio transport implementation.\n\nImportant implementation note discovered during development: When one tool needs to call another tool's logic, you cannot simply call the decorated function directly. The @mcp.tool() decorator wraps the function in a FunctionTool object that is not directly callable. The solution is to extract the shared logic into a plain helper function (prefixed with underscore by convention, e.g., _find_memory_by_id) and have both tools call that helper. This pattern is demonstrated in our get_memory and get_optimized_memory tools.\n\nFuture considerations: If we need more advanced features like WebSocket transport for real-time updates, custom authentication middleware, or integration with async frameworks like FastAPI, we might need to consider the raw SDK or a hybrid approach. For now, FastMCP serves our needs excellently and keeps the codebase clean and maintainable.",
      "tags": ["architecture", "fastmcp", "mcp-server"],
      "project": "memory-server",
      "created_at": "2026-01-09T10:20:00Z",
      "updated_at": "2026-01-15T11:00:00Z"
    },
    {
      "id": "mem-004",
      "type": "note",
      "title": "Course Structure and Learning Objectives - Instructor Notes",
      "summary": "4-segment course outline: CLI basics, MCP servers, agentic workflows, production skills. Learning objectives and timing for each segment.",
      "content": "This document contains detailed instructor notes for the O'Reilly Live Learning course 'Claude Code and Large-Context Reasoning'. The course is structured as a 4-hour intensive training session divided into four main segments, each building on the previous one to create a cohesive learning journey from basic CLI usage to production-ready agentic workflows.\n\nSegment 1: Claude Code Quick Start (approximately 45-60 minutes)\nThis segment focuses on getting students up and running with Claude Code CLI. We begin by verifying their environment setup using the npm run segment1:verify command, which checks for the presence of ANTHROPIC_API_KEY and validates API connectivity. Students learn the fundamental Claude Code commands including how to start interactive sessions, how to use the /help command to discover available features, and how to configure their environment using CLAUDE.md files for project-specific instructions.\n\nKey learning objectives for Segment 1: Understand what Claude Code is and how it differs from the web interface. Install and configure Claude Code CLI successfully. Use basic commands for code generation, explanation, and modification. Create and customize CLAUDE.md files for project context. Understand the role of the .claude directory for storing configuration, commands, and agents.\n\nSegment 2: MCP (Model Context Protocol) (approximately 60-75 minutes)\nThis segment introduces the Model Context Protocol and hands-on MCP server development. Students will build and run the Memory Server we've been developing, understanding the three primitives (tools, resources, prompts) through practical implementation. The npm run segment2:memory command starts the memory server, and we use the MCP Inspector for interactive testing and debugging.\n\nKey learning objectives for Segment 2: Understand the MCP architecture and its role in extending Claude's capabilities. Implement tools that Claude can invoke to perform actions. Create resources that expose read-only data. Build prompts that provide reusable templates. Debug MCP servers using the MCP Inspector. Register MCP servers with Claude Code using claude mcp add.\n\nSegment 3: Agents (approximately 45-60 minutes)\nThis segment covers agentic workflows and autonomous operations. We explore how Claude can operate with greater autonomy while respecting permission boundaries. The npm run segment3:agent-loop command demonstrates the core agent loop pattern, and npm run segment3:boundaries shows how to configure permission guardrails.\n\nKey learning objectives for Segment 3: Understand the agent loop pattern (observe, think, act, repeat). Configure permission boundaries for safe autonomous operation. Implement approval workflows for sensitive operations. Monitor and debug agent behavior. Understand the tradeoffs between autonomy and control.\n\nSegment 4: Skills and Production Workflows (approximately 45-60 minutes)\nThe final segment brings everything together with custom skills and production-ready patterns. Students learn to create multi-file skills in the .claude/commands directory and build custom agents in .claude/agents that leverage those skills.\n\nKey learning objectives for Segment 4: Create custom skills with supporting scripts and documentation. Build specialized agents for specific workflows (code review, release management, etc.). Integrate Claude Code into CI/CD pipelines. Implement cost management and token optimization. Deploy production-ready agentic systems with proper monitoring and error handling.",
      "tags": ["course-content", "instructor-notes"],
      "project": "claude-code-course",
      "created_at": "2026-01-07T11:00:00Z",
      "updated_at": "2026-01-15T08:00:00Z"
    },
    {
      "id": "mem-005",
      "type": "snippet",
      "title": "Python MCP Tool Implementation - Complete Reference Pattern",
      "summary": "Complete FastMCP tool implementation reference with logging to stderr, type hints, helper functions, error handling, and Pydantic models.",
      "content": "This comprehensive code reference demonstrates the complete pattern for implementing MCP tools in Python using the FastMCP framework. The example includes all best practices learned during the development of our Memory Server, including proper type hints, error handling, logging configuration, and the helper function pattern for inter-tool communication.\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nExample MCP Server demonstrating best practices for tool implementation.\n\nThis server shows the complete pattern including:\n- Proper logging configuration (stderr, not stdout)\n- Type hints for all parameters and return values\n- Helper functions for shared logic\n- Comprehensive error handling\n- Structured response formats\n\"\"\"\n\nimport json\nimport logging\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Optional, Literal\n\nfrom fastmcp import FastMCP\nfrom pydantic import BaseModel, Field\n\n# CRITICAL: Configure logging to stderr\n# stdout is reserved for JSON-RPC communication\nlogging.basicConfig(\n    level=logging.WARNING,\n    stream=sys.stderr,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n# Initialize FastMCP server with descriptive name and instructions\nmcp = FastMCP(\n    name=\"Example Server\",\n    instructions=\"Demonstrate MCP tool implementation best practices.\"\n)\n\n# Data storage path\nDATA_FILE = Path(__file__).parent / \"data\" / \"items.json\"\n\n\n# =============================================================================\n# DATA MODELS - Use Pydantic for automatic validation\n# =============================================================================\n\nclass Item(BaseModel):\n    \"\"\"Data model for stored items.\"\"\"\n    id: str = Field(description=\"Unique identifier\")\n    name: str = Field(description=\"Item name\")\n    value: int = Field(description=\"Item value\", ge=0)\n    created_at: str = Field(description=\"ISO 8601 timestamp\")\n\n\n# =============================================================================\n# HELPER FUNCTIONS - Use these for shared logic between tools\n# =============================================================================\n\ndef _load_items() -> list[dict]:\n    \"\"\"Load items from JSON file. Returns empty list if file doesn't exist.\"\"\"\n    if DATA_FILE.exists():\n        with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f).get(\"items\", [])\n    return []\n\n\ndef _find_item_by_id(item_id: str) -> Optional[dict]:\n    \"\"\"\n    Find an item by ID.\n    \n    This is a HELPER FUNCTION (not a tool) that can be called\n    from multiple tools without the FunctionTool callable issue.\n    \"\"\"\n    items = _load_items()\n    for item in items:\n        if item[\"id\"].lower() == item_id.lower():\n            return item\n    return None\n\n\n# =============================================================================\n# TOOLS - Decorated functions become MCP tools\n# =============================================================================\n\n@mcp.tool()\ndef get_item(item_id: str) -> dict:\n    \"\"\"\n    Retrieve an item by its ID.\n    \n    Args:\n        item_id: The unique identifier of the item\n        \n    Returns:\n        The item if found, or error information if not found.\n    \"\"\"\n    item = _find_item_by_id(item_id)\n    \n    if item:\n        return {\n            \"success\": True,\n            \"item\": item\n        }\n    \n    return {\n        \"success\": False,\n        \"error\": f\"Item '{item_id}' not found\"\n    }\n\n\n@mcp.tool()\ndef get_item_with_metadata(item_id: str, include_stats: bool = False) -> dict:\n    \"\"\"\n    Retrieve an item with optional metadata.\n    \n    This tool demonstrates calling the helper function (not the tool)\n    to get item data, then enriching it with additional information.\n    \n    Args:\n        item_id: The unique identifier of the item\n        include_stats: Whether to include usage statistics\n        \n    Returns:\n        The item with metadata, or error information.\n    \"\"\"\n    # Use helper function, NOT the get_item tool\n    item = _find_item_by_id(item_id)\n    \n    if not item:\n        return {\n            \"success\": False,\n            \"error\": f\"Item '{item_id}' not found\"\n        }\n    \n    result = {\n        \"success\": True,\n        \"item\": item,\n        \"retrieved_at\": datetime.utcnow().isoformat() + \"Z\"\n    }\n    \n    if include_stats:\n        result[\"stats\"] = {\n            \"total_items\": len(_load_items()),\n            \"item_age_days\": 0  # Calculate from created_at\n        }\n    \n    return result\n\n\n# =============================================================================\n# MAIN ENTRY POINT\n# =============================================================================\n\ndef main():\n    \"\"\"Run the MCP server.\"\"\"\n    # Suppress banner with log_level if desired\n    mcp.run()  # or mcp.run(log_level=\"ERROR\")\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nKey takeaways from this pattern: Always use helper functions for logic that needs to be shared between tools. Never call a @mcp.tool() decorated function directly from another tool. Configure logging to stderr to avoid interfering with JSON-RPC on stdout. Use Pydantic models for data validation and documentation. Return structured dictionaries with success/error fields for consistent error handling.",
      "tags": ["tool-use", "mcp-server", "python", "code-example"],
      "project": "memory-server",
      "created_at": "2026-01-11T09:30:00Z",
      "updated_at": "2026-01-15T12:00:00Z"
    },
    {
      "id": "mem-006",
      "type": "troubleshooting",
      "title": "Common MCP Server Issues and Solutions - Comprehensive Debug Guide",
      "summary": "Debug guide for MCP issues: FunctionTool callable error, server registration, env loading, stdio errors, banner suppression, API failures.",
      "content": "This troubleshooting guide documents all the common issues encountered during MCP server development and their solutions. This knowledge was accumulated during the development of the Memory Server for the Claude Code course and represents real-world debugging experience.\n\nISSUE 1: 'FunctionTool' object is not callable\nSymptoms: You get this error when one tool tries to call another tool function directly.\nRoot cause: The @mcp.tool() decorator wraps functions in a FunctionTool object that handles JSON-RPC protocol details. This wrapper is not directly callable as a Python function.\nSolution: Extract shared logic into a plain helper function (prefix with underscore by convention). Have both tools call the helper instead of each other.\nExample fix:\n```python\n# WRONG - This will fail\n@mcp.tool()\ndef tool_a():\n    result = tool_b()  # Error: FunctionTool not callable\n\n# CORRECT - Use helper function\ndef _shared_logic():\n    return {\"data\": \"value\"}\n\n@mcp.tool()\ndef tool_a():\n    return _shared_logic()\n\n@mcp.tool()\ndef tool_b():\n    return _shared_logic()\n```\n\nISSUE 2: Server not appearing in Claude Code\nSymptoms: After running `claude mcp add`, the server doesn't show up in `claude mcp list` or tools aren't available.\nRoot cause: Usually a configuration issue in the MCP server registration.\nSolution: Check ~/.config/claude/settings.json (Linux/Mac) or the equivalent Windows location. Verify the command and args are correct. Test the server independently with MCP Inspector first.\nDebug steps:\n1. Run `npx @modelcontextprotocol/inspector` with your server command\n2. Verify tools appear in the Inspector's Tools tab\n3. Check for startup errors in stderr output\n4. Ensure environment variables are set correctly\n\nISSUE 3: Environment variables not loading\nSymptoms: API keys and configuration values are None or missing despite being set in .env file.\nRoot cause: The .env file isn't being loaded, or it's being loaded from the wrong location.\nSolution: Use explicit path to .env file relative to the script location:\n```python\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\n# Load from same directory as script\nENV_FILE = Path(__file__).parent / \".env\"\nload_dotenv(ENV_FILE, override=False)\n```\nThe override=False parameter means system environment variables take precedence, which is usually what you want for production.\n\nISSUE 4: stdio transport errors or garbled output\nSymptoms: JSON-RPC errors, malformed messages, or Claude can't communicate with the server.\nRoot cause: Something is writing to stdout, which is reserved for JSON-RPC protocol messages.\nSolution: Ensure ALL logging and debug output goes to stderr:\n```python\nimport logging\nimport sys\n\nlogging.basicConfig(\n    level=logging.WARNING,\n    stream=sys.stderr,  # CRITICAL: Use stderr, not stdout\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\n\n# Also avoid print() statements - use logging instead\nlogger = logging.getLogger(__name__)\nlogger.info(\"This goes to stderr\")\n# print(\"This would break JSON-RPC!\")  # DON'T DO THIS\n```\n\nISSUE 5: FastMCP banner appearing in output\nSymptoms: A startup banner with FastMCP branding appears when the server starts.\nRoot cause: This is default FastMCP behavior for informational purposes.\nSolution: If it bothers you, suppress it by setting log level:\n```python\nmcp.run(log_level=\"ERROR\")\n```\nNote: The banner goes to stderr so it doesn't actually interfere with JSON-RPC, it's purely cosmetic.\n\nISSUE 6: Token optimization returning unchanged content\nSymptoms: get_optimized_memory returns the same content without optimization.\nRoot cause: Content is already under the token budget (default 1500 tokens).\nSolution: This is expected behavior, not an error. The optimization field in the response will show 'Content already within token budget'. If you want to test optimization, use content that exceeds 1500 tokens or lower the max_tokens parameter.\n\nISSUE 7: DeepSeek API connection failures\nSymptoms: Optimization fails with connection errors or 'DeepSeek client not initialized'.\nRoot cause: API key not set, incorrect base URL, or network issues.\nSolution: Verify your src/.env file contains:\n```\nOPENAI_API_KEY=your-deepseek-api-key\nOPENAI_BASE_URL=https://api.deepseek.com\n```\nTest connection with the test_apis tool which will report the specific error.",
      "tags": ["troubleshooting", "mcp-server", "debugging"],
      "project": "memory-server",
      "created_at": "2026-01-05T13:45:00Z",
      "updated_at": "2026-01-15T14:00:00Z"
    },
    {
      "id": "mem-007",
      "type": "note",
      "title": "Project File Structure and Organization - Developer Reference",
      "summary": "Project directory layout: .claude/ config, segment folders, src/ Python code, npm scripts, and configuration files explained.",
      "content": "This document provides a comprehensive overview of the project file structure for the Claude Code course repository. Understanding this organization is essential for navigating the codebase and knowing where to find specific functionality.\n\nROOT DIRECTORY STRUCTURE:\n```\nclaude-code/\n├── .claude/                    # Claude Code configuration\n│   ├── agents/                 # Custom agent definitions\n│   │   ├── claude-code-tutor.md\n│   │   ├── code-quality-coach.md\n│   │   └── release-manager.md\n│   └── commands/               # Custom skills/commands\n│       ├── code-review/\n│       └── deploy-prep/\n├── demos/                      # Demo scripts and examples\n├── docs/                       # Documentation and resources\n├── segment_1_quickstart/       # Segment 1: CLI basics\n├── segment_2_mcp/              # Segment 2: MCP servers\n│   └── memory_server/          # TypeScript memory server\n├── segment_3_agents/           # Segment 3: Agentic workflows\n├── segment_4_skills_agents/    # Segment 4: Production patterns\n├── src/                        # Python source code\n│   ├── data/                   # Data files\n│   │   └── memory_items.json   # Memory server data\n│   ├── api_utils.py            # DeepSeek/GitHub clients\n│   ├── memory_server.py        # FastMCP memory server\n│   └── .env                    # Environment variables\n├── CLAUDE.md                   # Project instructions for Claude\n├── package.json                # npm scripts and dependencies\n└── pyproject.toml              # Python project configuration\n```\n\nSRC DIRECTORY DETAILS:\nThe src/ directory contains our Python-based MCP server implementation:\n\nmemory_server.py - The main FastMCP server implementing:\n- 4 Resources: memory://items, memory://tags, memory://types, memory://stats\n- 10 Tools: add_memory, get_memory, search_memory, get_optimized_memory, update_memory, delete_memory, list_by_tag, list_by_type, reset_memory, test_apis\n- 4 Prompts: code_review_context, refactoring_plan, mcp_tool_design, codebase_analysis\n\napi_utils.py - Utility classes for external API integration:\n- DeepSeekClient: Token optimization using DeepSeek LLM\n- GitHubClient: GitHub API integration (for future use)\n- OptimizedCache: In-memory cache with TTL for optimization results\n\ndata/memory_items.json - The JSON data store containing:\n- memory_items[]: Array of memory objects\n- tags[]: Predefined tag definitions with descriptions\n- types[]: Memory type definitions with descriptions\n- metadata{}: Version and statistics\n\n.env - Environment configuration (not committed to git):\n- OPENAI_API_KEY: DeepSeek API key\n- OPENAI_BASE_URL: DeepSeek API endpoint\n- LLM_MODEL: Model to use (deepseek-chat)\n- GITHUB_TOKEN: GitHub personal access token\n\nNPM SCRIPTS (from package.json):\nThe following npm scripts are available for running demos and servers:\n- npm run segment1:verify - Verify API setup\n- npm run segment2:memory - Start Python memory server\n- npm run segment3:agent-loop - Agent loop demonstration\n- npm run segment4:workflows - Production workflow demos\n- npm run mcp:memory - Start memory server standalone\n\nCLAUDE CODE CONFIGURATION:\nThe .claude/ directory contains:\n- agents/: Markdown files defining custom agents with specialized behaviors\n- commands/: Multi-file skills with scripts, documentation, and templates\n\nThese integrate with Claude Code to provide domain-specific capabilities like code review workflows, release preparation, and interactive tutoring.",
      "tags": ["project-structure", "documentation", "developer-reference"],
      "project": "claude-code-course",
      "created_at": "2026-01-12T08:15:00Z",
      "updated_at": "2026-01-15T09:00:00Z"
    },
    {
      "id": "mem-008",
      "type": "prd",
      "title": "Memory Server Feature Requirements - Complete Specification",
      "summary": "Memory Server PRD: CRUD tools, search/discovery, resources, DeepSeek optimization, prompt templates. Success criteria included.",
      "content": "This Product Requirements Document specifies the complete feature set for the MCP Memory Server component of the Claude Code course. The Memory Server serves as the primary hands-on project that students will build, extend, and interact with throughout the course.\n\nPROJECT OVERVIEW:\nThe Memory Server is an MCP-compliant server that provides persistent storage for project notes, code patterns, architectural decisions, and contextual information. It demonstrates all three MCP primitives (tools, resources, prompts) and integrates with external APIs (DeepSeek) for advanced functionality.\n\nCORE REQUIREMENTS:\n\n1. Data Storage (Priority: Critical)\n- Store memory items in JSON format for human readability\n- Support multiple memory types: note, prd, snippet, decision, pattern, config, troubleshooting\n- Implement tagging system for categorization\n- Track creation and modification timestamps\n- Associate memories with projects for filtering\n- Maintain data integrity during concurrent access\n\n2. CRUD Operations (Priority: Critical)\n- CREATE: add_memory tool with validation\n- READ: get_memory tool for single item retrieval\n- UPDATE: update_memory tool for modifications\n- DELETE: delete_memory tool (in-memory only, preserves source file)\n- RESET: reset_memory tool to restore original state\n\n3. Search and Discovery (Priority: High)\n- Keyword search across title and content\n- Filter by tag, type, and project\n- Relevance scoring for search results\n- List operations: list_by_tag, list_by_type\n\n4. Resources (Priority: High)\n- memory://items - List all memory items with metadata\n- memory://tags - Available tags with descriptions\n- memory://types - Memory type definitions\n- memory://stats - Usage statistics and counts\n\n5. Token Optimization (Priority: Medium)\n- Integration with DeepSeek LLM for content compression\n- Preserve technical content (code, commands, configs)\n- Remove verbose prose and redundant explanations\n- Caching with configurable TTL\n- Graceful fallback when API unavailable\n\n6. Prompt Templates (Priority: Medium)\n- code_review_context - Generate code review prompts\n- refactoring_plan - Create refactoring analysis prompts\n- mcp_tool_design - Design new MCP tools\n- codebase_analysis - Analyze codebases with large context\n\nTECHNICAL REQUIREMENTS:\n\n1. Framework: FastMCP (Python)\n- Use @mcp.tool(), @mcp.resource(), @mcp.prompt() decorators\n- Implement proper error handling with structured responses\n- Log to stderr to preserve stdout for JSON-RPC\n\n2. External Integrations:\n- DeepSeek API via OpenAI-compatible SDK\n- GitHub API for future repository integration\n- tiktoken for accurate token counting\n\n3. Configuration:\n- Environment variables via .env file\n- Sensible defaults for all optional parameters\n- Clear error messages for missing configuration\n\n4. Testing:\n- Compatible with MCP Inspector for interactive testing\n- All tools return consistent response format\n- Comprehensive error responses with suggestions\n\nNON-FUNCTIONAL REQUIREMENTS:\n\n1. Performance:\n- Response time < 100ms for local operations\n- Optimization API calls < 5 seconds\n- Efficient memory usage for large data sets\n\n2. Reliability:\n- Graceful degradation when external APIs unavailable\n- No data loss during normal operation\n- Clear error reporting for all failure modes\n\n3. Maintainability:\n- Well-documented code with docstrings\n- Consistent coding style (type hints, formatting)\n- Modular architecture for easy extension\n\nSUCCESS CRITERIA:\n- All 10 tools functional and tested\n- All 4 resources accessible\n- All 4 prompts properly formatted\n- Token optimization demonstrably reduces content size\n- Students can extend with new tools in < 15 minutes",
      "tags": ["prd", "requirements", "memory-server"],
      "project": "memory-server",
      "created_at": "2026-01-03T09:00:00Z",
      "updated_at": "2026-01-15T10:00:00Z"
    },
    {
      "id": "mem-009",
      "type": "snippet",
      "title": "MCP Inspector Usage - Complete Command Reference",
      "summary": "MCP Inspector command reference for testing servers. Covers startup commands, interface tabs, testing workflow, and troubleshooting.",
      "content": "This reference document provides comprehensive instructions for using the MCP Inspector to test and debug MCP servers. The MCP Inspector is an essential development tool that provides a web-based interface for interacting with MCP servers during development.\n\nINSTALLATION AND STARTUP:\nThe MCP Inspector is distributed as an npm package and can be run directly using npx without installation. The basic command pattern is:\n\n```bash\n# Basic usage with a Node.js server\nnpx @modelcontextprotocol/inspector npx tsx ./server.ts\n\n# Usage with a Python server\nnpx @modelcontextprotocol/inspector python ./memory_server.py\n\n# Usage with uv for Python (recommended for our project)\nnpx @modelcontextprotocol/inspector uv run python src/memory_server.py\n\n# Specifying a port (default is 5173)\nnpx @modelcontextprotocol/inspector --port 3000 python ./server.py\n```\n\nFor our Memory Server project, the recommended startup command is:\n```bash\ncd c:/github/claude-code\nnpx @modelcontextprotocol/inspector uv run python src/memory_server.py\n```\n\nINSPECTOR INTERFACE:\nOnce started, open your browser to http://localhost:5173 (or the specified port). The interface has several tabs:\n\n1. TOOLS TAB:\n- Lists all registered tools with their schemas\n- Click a tool to see its parameters\n- Fill in parameter values and click 'Call Tool'\n- Response appears in the right panel\n- Use this to test individual tool functionality\n\n2. RESOURCES TAB:\n- Lists all registered resources\n- Click a resource to fetch its content\n- Content appears in the right panel\n- Useful for verifying resource data formatting\n\n3. PROMPTS TAB:\n- Lists all registered prompts\n- Shows required and optional arguments\n- Fill in arguments to generate the prompt\n- Preview the generated prompt text\n\n4. LOGS TAB:\n- Shows JSON-RPC message traffic\n- Useful for debugging protocol issues\n- Filter by message type\n- Export logs for analysis\n\nTESTING WORKFLOW:\n\n1. Start the Inspector with your server\n2. Verify all expected tools appear in the Tools tab\n3. Test each tool with various inputs:\n   - Valid inputs (happy path)\n   - Invalid inputs (error handling)\n   - Edge cases (empty strings, missing optional params)\n4. Check resources return expected data\n5. Verify prompts generate correctly\n\nEXAMPLE TEST SEQUENCE FOR MEMORY SERVER:\n\n```\n# 1. Test get_memory with valid ID\nTool: get_memory\nParams: { \"memory_id\": \"mem-001\" }\nExpected: { \"success\": true, \"memory\": {...} }\n\n# 2. Test get_memory with invalid ID\nTool: get_memory\nParams: { \"memory_id\": \"nonexistent\" }\nExpected: { \"success\": false, \"error\": \"...not found\" }\n\n# 3. Test search_memory\nTool: search_memory\nParams: { \"search_term\": \"MCP\", \"tag\": \"mcp-server\" }\nExpected: { \"success\": true, \"count\": N, \"memories\": [...] }\n\n# 4. Test get_optimized_memory\nTool: get_optimized_memory\nParams: { \"memory_id\": \"mem-001\", \"max_tokens\": 500 }\nExpected: { \"success\": true, \"optimization\": { \"reduction\": \"XX%\" } }\n\n# 5. Test resources\nResource: memory://stats\nExpected: Formatted statistics markdown\n```\n\nTROUBLESHOOTING INSPECTOR ISSUES:\n\n- If tools don't appear: Check server startup for errors in terminal\n- If calls hang: Server might have crashed; check terminal output\n- If responses are garbled: Something is writing to stdout; check logging config\n- If port is in use: Specify a different port with --port flag\n- If Python not found: Use full path or activate virtual environment first",
      "tags": ["mcp-inspector", "debugging", "tool-use"],
      "project": "memory-server",
      "created_at": "2026-01-04T10:00:00Z",
      "updated_at": "2026-01-15T13:00:00Z"
    },
    {
      "id": "mem-010",
      "type": "decision",
      "title": "In-Memory State vs File Persistence - Architectural Decision",
      "summary": "ADR for in-memory state vs file persistence. Chose memory-only for demo safety, predictability, and simplified implementation.",
      "content": "This architectural decision record documents our choice to separate in-memory state from file persistence in the Memory Server. This decision has significant implications for how the server behaves during development, testing, and production use.\n\nCONTEXT:\nWhen building the Memory Server, we needed to decide how to handle data persistence. The options were:\n1. Direct file I/O: Read from and write to JSON file on every operation\n2. In-memory with periodic sync: Load data into memory, write periodically\n3. In-memory with explicit save: Load data into memory, require explicit save command\n4. In-memory only: Load from file at startup, never write back (our choice)\n\nDECISION:\nWe chose option 4: in-memory only operation with file-based initial load. Data is loaded from memory_items.json when the server starts and stored in a module-level list (_memory_store). All CRUD operations modify this in-memory list. Changes are never automatically written back to the source file. A reset_memory tool allows reloading the original file contents.\n\nRATIONALE:\n\n1. Safety during demos and experimentation:\nStudents can freely add, modify, and delete memory items during the course without worrying about corrupting the base data. When they want to start fresh, they simply call reset_memory or restart the server. This removes friction from experimentation and learning.\n\n2. Predictable demo behavior:\nEach time we demonstrate the server in the course, it starts with the same known state. This makes demos reproducible and avoids 'works on my machine' issues. Instructors can prepare specific scenarios that will be consistent across all student environments.\n\n3. Simplified implementation:\nNo need to handle file locking, atomic writes, or corruption recovery. The JSON file is only read, never written, so we don't need to worry about partial writes or concurrent access issues. This keeps the code simple and focused on teaching MCP concepts.\n\n4. Easy testing:\nEach test run starts with a clean slate. Tests don't need cleanup logic to restore state. Multiple test processes can run simultaneously without file conflicts. Mock data can be easily injected by modifying _memory_store directly.\n\nTRADEOFFS ACCEPTED:\n\n1. No persistence across restarts:\nAny changes made during a session are lost when the server restarts. For a course demo, this is acceptable and even desirable. For production use, this would need to be addressed.\n\n2. Memory usage:\nAll data must fit in memory. For our course scenario with ~10-20 memory items, this is trivial. For production with thousands of items, we'd need pagination or a proper database.\n\n3. No multi-instance coordination:\nIf multiple server instances run simultaneously, they have independent state. This is fine for development but wouldn't work for production deployments.\n\nIMPLEMENTATION DETAILS:\n\n```python\n# Module-level in-memory store\n_memory_store: list[dict] = []\n\ndef get_memory_store() -> list[dict]:\n    \"\"\"Get the in-memory store, initializing from file if needed.\"\"\"\n    global _memory_store\n    if not _memory_store:\n        _memory_store = load_memories()  # Load from JSON file\n    return _memory_store\n\ndef reset_memory_store() -> None:\n    \"\"\"Reset memory store to original data.\"\"\"\n    global _memory_store\n    _memory_store = load_memories()  # Reload from JSON file\n```\n\nFUTURE CONSIDERATIONS:\nIf we wanted to add persistence, we could:\n1. Add a save_memory tool that writes current state to file\n2. Implement auto-save on a timer or after N changes\n3. Use SQLite for more robust persistence\n4. Add a 'production mode' flag that enables persistence\n\nFor the course purposes, the current approach is ideal and we recommend keeping it as-is.",
      "tags": ["architecture", "persistence", "memory-server"],
      "project": "memory-server",
      "created_at": "2026-01-06T14:00:00Z",
      "updated_at": "2026-01-15T11:30:00Z"
    }
  ],
  "tags": [
    {
      "name": "mcp-server",
      "description": "Model Context Protocol server development, tools, resources, prompts"
    },
    {
      "name": "tool-use",
      "description": "Function calling, tool schemas, Zod validation, parameter handling"
    },
    {
      "name": "architecture",
      "description": "System design, architectural decisions, patterns"
    },
    {
      "name": "fastmcp",
      "description": "FastMCP framework usage, decorators, configuration"
    },
    {
      "name": "deepseek",
      "description": "DeepSeek LLM integration, token optimization, API usage"
    },
    {
      "name": "token-optimization",
      "description": "Token counting, content compression, efficiency strategies"
    },
    {
      "name": "configuration",
      "description": "Environment variables, settings, configuration files"
    },
    {
      "name": "troubleshooting",
      "description": "Debugging, common errors, solutions, fixes"
    },
    {
      "name": "course-content",
      "description": "Course structure, learning objectives, segment organization"
    },
    {
      "name": "instructor-notes",
      "description": "Teaching notes, demo scripts, presentation guidance"
    },
    {
      "name": "python",
      "description": "Python implementation, best practices, patterns"
    },
    {
      "name": "code-example",
      "description": "Working code snippets, reference implementations"
    },
    {
      "name": "debugging",
      "description": "Debug techniques, logging, error investigation"
    },
    {
      "name": "project-structure",
      "description": "File organization, directory layout, code organization"
    },
    {
      "name": "documentation",
      "description": "Documentation, references, guides"
    },
    {
      "name": "developer-reference",
      "description": "Quick reference, cheat sheets, lookup information"
    },
    {
      "name": "prd",
      "description": "Product requirements, specifications, feature definitions"
    },
    {
      "name": "requirements",
      "description": "Functional and non-functional requirements"
    },
    {
      "name": "mcp-inspector",
      "description": "MCP Inspector tool usage, testing, debugging"
    },
    {
      "name": "persistence",
      "description": "Data storage, state management, file handling"
    }
  ],
  "types": [
    {
      "name": "note",
      "description": "General project notes and observations"
    },
    {
      "name": "prd",
      "description": "Product requirements documents and project specifications"
    },
    {
      "name": "snippet",
      "description": "Code snippets and implementation examples"
    },
    {
      "name": "decision",
      "description": "Architecture decisions and technical choices"
    },
    {
      "name": "pattern",
      "description": "Design patterns and best practices"
    },
    {
      "name": "config",
      "description": "Configuration files and settings"
    },
    {
      "name": "troubleshooting",
      "description": "Error solutions and debugging guides"
    }
  ],
  "metadata": {
    "version": "2.0.0",
    "last_updated": "2026-01-15T14:00:00Z",
    "total_items": 10
  }
}
